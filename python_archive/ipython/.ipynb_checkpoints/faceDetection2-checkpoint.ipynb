{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "'''\n",
    "    python ==> 비주얼컴퓨팅, 프로젝트4 얼굴 사진 55x40 데이터를 700장 사용해 Deep Neural Network를 사용함으로써 예측모델을 만들어본 코드\n",
    "                             500번 반복하니 96% 정도의 예측율을 보여준다 굳굳\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# train\n",
    "train_images = []\n",
    "tlabels = []\n",
    "\n",
    "# train Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    train_images.append(scipy.misc.imread('train_image/train_'+ str(num)+'.bmp'))\n",
    "\n",
    "# train Label 데이터를 불러온다\n",
    "with open(\"train_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    tlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "train_images = np.array(train_images)\n",
    "train_images = train_images.reshape(700, 2200, )\n",
    "\n",
    "tlabels = np.array(tlabels)     # tlabels = (1,700)\n",
    "tlabels = tlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "train_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    train_labels[num][int(tlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# test\n",
    "test_images = []\n",
    "testlabels = []\n",
    "\n",
    "\n",
    "# test Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    test_images.append(scipy.misc.imread('test_image/test_'+ str(num)+'.bmp'))\n",
    "\n",
    "\n",
    "# test Label 데이터를 불러온다\n",
    "with open(\"test_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    testlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "test_images = np.array(test_images)\n",
    "test_images = test_images.reshape(700, 2200, )\n",
    "\n",
    "testlabels = np.array(testlabels)     # tlabels = (1,700)\n",
    "testlabels = testlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "test_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    test_labels[num][int(testlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "# 중요! Image 데이터들은 0~255 사이의 값이므로 255로 나눠주면서 정규화를 한다. 학습이 매우 잘된다\n",
    "train_images = train_images / 255.\n",
    "test_images =  test_images / 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "\n",
    "_num_examples = 700   # 데이터 갯수\n",
    "_index_in_epoch = 0   # epoch\n",
    "_images = train_images  # Image 변수 \n",
    "_labels = train_labels  # Label 변수\n",
    "_epochs_completed = 0   \n",
    "\n",
    "# batch 연산을 수행하는 함수\n",
    "# 호출될 때마다 랜덤으로 batch_size의 (Image, Label) 데이터를 반환한다\n",
    "def next_batch(batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    global _index_in_epoch\n",
    "    global _images\n",
    "    global _labels\n",
    "    global _epochs_completed\n",
    "\n",
    "    start = _index_in_epoch\n",
    "    _index_in_epoch += batch_size\n",
    "\n",
    "    if _index_in_epoch > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "\n",
    "      # Shuffle the data\n",
    "      perm = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm)\n",
    "      _images = _images[perm]\n",
    "      _labels = _labels[perm]\n",
    "\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size\n",
    "      assert batch_size <= _num_examples\n",
    "\n",
    "    end = _index_in_epoch\n",
    "    return _images[start:end], _labels[start:end]\n",
    "\n",
    "\n",
    "# 가중치를 초기화하는 함수 (정규분포 stddev=0.1로 초기화한다)\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 바이어스를 초기화하는 함수 (0.1로 초기화한다)\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 컨벌루션을 실행하는 함수\n",
    "# padding = 'SAME' 입력과 출력의 이미지 크기가 같도록 해준다\n",
    "# (28,28) --> (28,28)\n",
    "# padding = 'VALID' 필터의 크기만큼 이미지 크기가 감소한다\n",
    "def conv2d_valid(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "\n",
    "def conv2d_same(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "# max pooling을 실행하는 함수\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# Tensorflow 코드\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "x = tf.placeholder(\"float32\", [None, 2200]) # mnist data image of shape 55 x 40 = 2200\n",
    "y = tf.placeholder(\"float32\", [None, 100]) \n",
    "\n",
    "W = tf.Variable(tf.zeros([2200,100]))\n",
    "b = tf.Variable(tf.zeros([100]))\n",
    "\n",
    "\n",
    "# 1st conv layer ----------------------\n",
    "W_conv1 = weight_variable([8,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# -1 : 아직 디멘젼이 결정되지 않았다\n",
    "# 1 : 흑백이므로 1을 삽입한다. 칼라이면 3을 삽입한다\n",
    "# x은 2200x1인데 55x40x1로 행렬을 다시 만들어준다\n",
    "x_image = tf.reshape(x, [-1, 55, 40, 1])\n",
    "\n",
    "# y = x*w + b에 ReLU를 적용한다\n",
    "# (55,40) ==> (48,36)\n",
    "h_conv1 = tf.nn.relu(conv2d_valid(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# (48,36) ==> (24, 18)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd conv layer -----------------------\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# (24, 18) ==> (24, 18)\n",
    "h_conv2 = tf.nn.relu(conv2d_same(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# (24, 18) ==> (12, 9)\n",
    "\n",
    "\n",
    "\n",
    "# 1st fully connected layer -----------------------\n",
    "W_fc1 = weight_variable([12*9*64, 3000])\n",
    "b_fc1 = bias_variable([3000])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 12*9*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 위 연산으로 1024x1의 벡터가 생성된다\n",
    "\n",
    "\n",
    "\n",
    "# Dropout ------------------------\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd fully connected layer --------------\n",
    "W_fc2 = weight_variable([3000, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning_rate 잘 설정하는게 중요하다.. 0.1로 하니 전혀 변화가 없었다\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# 정답률을 계산한다  y_conv  vs  y\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 training_accuracy 0.0 cost 38.1143\n",
      "step 200 training_accuracy 0.8 cost 1.65511\n",
      "step 400 training_accuracy 1.0 cost 0.167006\n",
      "step 600 training_accuracy 1.0 cost 0.0439493\n",
      "step 800 training_accuracy 1.0 cost 0.00482064\n",
      "step 1000 training_accuracy 1.0 cost 0.0024992\n",
      "step 1200 training_accuracy 1.0 cost 0.001766\n",
      "step 1400 training_accuracy 1.0 cost 0.00100987\n",
      "step 1600 training_accuracy 1.0 cost 0.000536501\n",
      "step 1800 training_accuracy 1.0 cost 0.000469296\n",
      "step 2000 training_accuracy 1.0 cost 0.000384554\n",
      "step 2200 training_accuracy 1.0 cost 0.000385318\n",
      "step 2400 training_accuracy 1.0 cost 0.000236509\n",
      "step 2600 training_accuracy 1.0 cost 0.000127604\n",
      "step 2800 training_accuracy 1.0 cost 0.000108882\n",
      "step 3000 training_accuracy 1.0 cost 6.8571e-05\n",
      "step 3200 training_accuracy 1.0 cost 6.5755e-05\n",
      "step 3400 training_accuracy 1.0 cost 3.95144e-05\n",
      "step 3600 training_accuracy 1.0 cost 3.31005e-05\n",
      "step 3800 training_accuracy 1.0 cost 9.37741e-05\n",
      "step 4000 training_accuracy 1.0 cost 6.35738e-05\n",
      "step 4200 training_accuracy 1.0 cost 0.000299872\n",
      "step 4400 training_accuracy 1.0 cost 0.000561786\n",
      "step 4600 training_accuracy 1.0 cost 2.37376e-05\n",
      "step 4800 training_accuracy 1.0 cost 1.17395e-05\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "batch_size = 50      # 한 루프에 몇개의 (Image, Label) 데이터를 학습하는지 설정\n",
    "display_step = 200    # 루프를 돌면서 화면에 표시할 빈도 설정\n",
    "\n",
    "for i in range(5000):\n",
    "\tcostVal = 0.\n",
    "\tbatch = next_batch(batch_size)\n",
    "\t# 20번 돌릴 때마다 결과를 확인한다\n",
    "\tif i % display_step == 0:\n",
    "\t\ttrain_accuracy = sess.run(accuracy,feed_dict={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "\t\tcostVal = sess.run(cost, feed_dict={x: batch[0], y: batch[1], keep_prob:1.0})\n",
    "    \n",
    "\t\tprint('step', i , 'training_accuracy', train_accuracy,'cost', costVal)\n",
    "        \n",
    "        # 실제 학습과정 함수, dropout 50%를 토대로 학습한다\n",
    "\tsess.run(optimizer,feed_dict={x:batch[0],y:batch[1], keep_prob:0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.992857\n"
     ]
    }
   ],
   "source": [
    "# 전부 학습이 끝나면 테스트 데이터를 넣어 정확도를 계산한다\n",
    "test_accuracy = sess.run(accuracy,feed_dict={x: test_images, y: test_labels, keep_prob: 1.0})\n",
    "print('test accuracy', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [54]\n",
      "Prediction:  [54]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMMAAAD8CAYAAADKUxDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTMWdwZiKO4Mxlf8DlRxLIwG/pHAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdcc2320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# 임의의 얼굴 하나를 출력한 다음 맞혀보는 코드 \n",
    "r = random.randint(0, _num_examples -1)\n",
    "print (\"Label: \", sess.run(tf.argmax(test_labels[r:r+1], 1)))\n",
    "print (\"Prediction: \", sess.run(tf.argmax(y_conv, 1), {x:test_images[r:r+1], keep_prob:1.0}))\n",
    "\n",
    "plt.imshow(test_images[r:r+1].reshape(55, 40), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
