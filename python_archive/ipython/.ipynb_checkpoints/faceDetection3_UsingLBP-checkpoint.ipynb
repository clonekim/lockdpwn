{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "'''\n",
    "    python ==> 비주얼컴퓨팅, 프로젝트4 얼굴 사진 55x40 데이터를 700장 사용해 LBP 연산을 수행한 후 Deeper NN에 넣어본 코드\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import random\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# train\n",
    "train_images = []\n",
    "tlabels = []\n",
    "\n",
    "# train Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    train_images.append(scipy.misc.imread('D:\\\\edward\\\\visualComputing_faceDetection\\\\train_image\\\\train_'+ str(num)+'.bmp'))\n",
    "\n",
    "# train Label 데이터를 불러온다\n",
    "with open(\"D:\\\\edward\\\\visualComputing_faceDetection\\\\train_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    tlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "train_images = np.array(train_images)\n",
    "# LBP 연산을 위해 train_images2 선언해준다\n",
    "train_images2 = np.array(train_images)\n",
    "train_images = train_images.reshape(700, 2200, )\n",
    "\n",
    "\n",
    "tlabels = np.array(tlabels)     # tlabels = (1,700)\n",
    "tlabels = tlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "train_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    train_labels[num][int(tlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# test\n",
    "test_images = []\n",
    "testlabels = []\n",
    "\n",
    "\n",
    "# test Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    test_images.append(scipy.misc.imread('D:\\\\edward\\\\visualComputing_faceDetection\\\\test_image\\\\test_'+ str(num)+'.bmp'))\n",
    "\n",
    "\n",
    "# test Label 데이터를 불러온다\n",
    "with open(\"D:\\\\edward\\\\visualComputing_faceDetection\\\\test_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    testlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "test_images = np.array(test_images)\n",
    "# LBP 연산을 위해 test_images2 선언해준다\n",
    "test_images2 = np.array(test_images)\n",
    "test_images = test_images.reshape(700, 2200, )\n",
    "\n",
    "testlabels = np.array(testlabels)     # tlabels = (1,700)\n",
    "testlabels = testlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "test_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    test_labels[num][int(testlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "# 중요! Image 데이터들은 0~255 사이의 값이므로 255로 나눠주면서 정규화를 한다. 학습이 매우 잘된다\n",
    "train_images = train_images / 255.\n",
    "test_images =  test_images / 255.\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# LBP izing\n",
    "\n",
    "# 해당 사진 데이터의 크기를 받아온 후 lbp_img를 설정한다\n",
    "num_img, rows, cols = train_images2.shape\n",
    "\n",
    "newrows = int((rows-1)/2)\n",
    "newcols = int((cols-1)/2)\n",
    "\n",
    "# 트레이닝용 변수 선언\n",
    "lbp_img = np.array(np.zeros(700 * newcols * newrows).reshape(700, newrows, newcols))\n",
    "\n",
    "# 테스트용 변수 선언\n",
    "lbp_img_test = lbp_img\n",
    "\n",
    "# 한 점으로부터 2x2의 픽셀데이터를 반환하는 함수 \n",
    "def neighborPixels(img, x, y):\n",
    "    npixels = []\n",
    "\n",
    "    npixels.append(img[x-1, y-1])\n",
    "    npixels.append(img[x, y-1])\n",
    "    npixels.append(img[x+1, y-1])\n",
    "    npixels.append(img[x-1, y])\n",
    "    npixels.append(img[x+1, y])\n",
    "    npixels.append(img[x-1, y+1])\n",
    "    npixels.append(img[x, y+1])\n",
    "    npixels.append(img[x+1, y+1])\n",
    "\n",
    "    return np.array(npixels)\n",
    "\n",
    "\n",
    "# 중앙 center 점보다 neighbor_p 값이 크면 1을, 아니면 0을 반환하는 함수\n",
    "def thresholded(center, neighbor_p):\n",
    "    out = []\n",
    "    for a in neighbor_p:\n",
    "        if a > center:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# LBP 메인 알고리즘\n",
    "for x in range(1, rows-1, 2):\n",
    "    for y in range(1, cols -1, 2):\n",
    "        for i in range(0, num_img - 1):\n",
    "            center = train_images2[i][x,y]   # 중앙 픽셀값을 받아온다\n",
    "            neighbor_p = neighborPixels(train_images2[i], x, y)  # 주변 점들의 값을 받아온다\n",
    "            values = thresholded(center, neighbor_p) # center 점보다 주변값이 크면 1 아니면 0 을 반환한다\n",
    "\n",
    "            weights = [1,2,4,8,16,32,64,128]\n",
    "            res = 0\n",
    "\n",
    "            for a in range(0, len(values)):\n",
    "                res += weights[a] + values[a]\n",
    "                lbp_img[i].itemset((x//2, y//2), res)\n",
    "\n",
    "\n",
    "# 데이터를 정규화시킨다\n",
    "lbp_img= lbp_img.reshape(700, 513)\n",
    "\n",
    "# LBP의 결과값이 전부 255보다 크므로 255를 빼서 데이터를 0 ~ 8 사이로 놓는다\n",
    "for i in range(0, num_img - 1):\n",
    "    for j in range(0, 513):\n",
    "            lbp_img[i][j] -= 255.\n",
    "\n",
    "# 데이터를 0 ~ 1 로 놓기 위해 8로 나눠준다\n",
    "lbp_img = lbp_img / 8.\n",
    "\n",
    "\n",
    "# Test용 LBP 연산도 똑같이 한다\n",
    "# LBP 메인 알고리즘\n",
    "for x in range(1, rows-1, 2):\n",
    "    for y in range(1, cols -1, 2):\n",
    "        for i in range(0, num_img - 1):\n",
    "            center = test_images2[i][x,y]   # 중앙 픽셀값을 받아온다\n",
    "            neighbor_p = neighborPixels(test_images2[i], x, y)  # 주변 점들의 값을 받아온다\n",
    "            values = thresholded(center, neighbor_p) # center 점보다 주변값이 크면 1 아니면 0 을 반환한다\n",
    "\n",
    "            weights = [1,2,4,8,16,32,64,128]\n",
    "            res = 0\n",
    "\n",
    "            for a in range(0, len(values)):\n",
    "                res += weights[a] + values[a]\n",
    "                lbp_img_test[i].itemset((x//2, y//2), res)\n",
    "\n",
    "\n",
    "# 데이터를 정규화시킨다\n",
    "lbp_img_test= lbp_img_test.reshape(700, 513)\n",
    "\n",
    "# LBP의 결과값이 전부 255보다 크므로 255를 빼서 데이터를 0 ~ 8 사이로 놓는다\n",
    "for i in range(0, num_img - 1):\n",
    "    for j in range(0, 513):\n",
    "            lbp_img_test[i][j] -= 255.\n",
    "\n",
    "# 데이터를 0 ~ 1 로 놓기 위해 8로 나눠준다\n",
    "lbp_img_test = lbp_img_test / 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "\n",
    "_num_examples = 700   # 데이터 갯수\n",
    "_index_in_epoch = 0   # epoch\n",
    "_images = lbp_img  # Image 변수 \n",
    "_labels = train_labels  # Label 변수\n",
    "_epochs_completed = 0   \n",
    "\n",
    "# batch 연산을 수행하는 함수\n",
    "# 호출될 때마다 랜덤으로 batch_size의 (Image, Label) 데이터를 반환한다\n",
    "def next_batch(batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    global _index_in_epoch\n",
    "    global _images\n",
    "    global _labels\n",
    "    global _epochs_completed\n",
    "\n",
    "    start = _index_in_epoch\n",
    "    _index_in_epoch += batch_size\n",
    "\n",
    "    if _index_in_epoch > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "\n",
    "      # Shuffle the data\n",
    "      perm = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm)\n",
    "      _images = _images[perm]\n",
    "      _labels = _labels[perm]\n",
    "\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size\n",
    "      assert batch_size <= _num_examples\n",
    "\n",
    "    end = _index_in_epoch\n",
    "    return _images[start:end], _labels[start:end]\n",
    "\n",
    "\n",
    "# 가중치를 초기화하는 함수 (정규분포 stddev=0.1로 초기화한다)\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 바이어스를 초기화하는 함수 (0.1로 초기화한다)\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 컨벌루션을 실행하는 함수\n",
    "# padding = 'SAME' 입력과 출력의 이미지 크기가 같도록 해준다\n",
    "# (28,28) --> (28,28)\n",
    "# padding = 'VALID' 필터의 크기만큼 이미지 크기가 감소한다\n",
    "def conv2d_valid(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "\n",
    "def conv2d_same(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "# max pooling을 실행하는 함수\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Tensorflow 코드\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "x = tf.placeholder(\"float32\", [None, 513]) # mnist data image of shape 55 x 40 = 2200\n",
    "y = tf.placeholder(\"float32\", [None, 100]) \n",
    "\n",
    "W = tf.Variable(tf.zeros([513,100]))\n",
    "b = tf.Variable(tf.zeros([100]))\n",
    "\n",
    "\n",
    "# 1st conv layer ----------------------\n",
    "W_conv1 = weight_variable([8,4,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# -1 : 아직 디멘젼이 결정되지 않았다\n",
    "# 1 : 흑백이므로 1을 삽입한다. 칼라이면 3을 삽입한다\n",
    "# x은 513x1인데 27x19x1로 행렬을 다시 만들어준다\n",
    "x_image = tf.reshape(x, [-1, 27, 19, 1])\n",
    "\n",
    "# y = x*w + b에 ReLU를 적용한다\n",
    "# (27,19) ==> (20,16)\n",
    "h_conv1 = tf.nn.relu(conv2d_valid(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# (20,16) ==> (10, 8)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd conv layer -----------------------\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# (10, 8) ==> (10, 8)\n",
    "h_conv2 = tf.nn.relu(conv2d_same(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# (10, 8) ==> (5, 4)\n",
    "\n",
    "\n",
    "\n",
    "# 1st fully connected layer -----------------------\n",
    "W_fc1 = weight_variable([5*4*64, 1000])\n",
    "b_fc1 = bias_variable([1000])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 5*4*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 위 연산으로 3000x1의 벡터가 생성된다\n",
    "\n",
    "\n",
    "\n",
    "# Dropout ------------------------\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd fully connected layer --------------\n",
    "W_fc2 = weight_variable([1000, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "# learning_rate 잘 설정하는게 중요하다.. 0.1로 하니 전혀 변화가 없었다\n",
    "# 1000인 경우\n",
    "    # 1e-5 : 4500번, 15.4%\n",
    "    # 1e-4 : 4500번, 62.2%\n",
    "    # 5e-3 : 4500번, 24.7%  .. 먼가 이상하다\n",
    "    # 1e-3 : 4500번, 61.7%\n",
    "    # 1e-2 : 2100번에서 갑자기 cost가 0.0으로 변한다 (2000번, 21.2%)\n",
    "    # 1e-1 : 학습이 안되서 포기\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# 정답률을 계산한다  y_conv  vs  y\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 training_accuracy 1.0 cost 7.10486e-07\n",
      "step 1000 training_accuracy 1.0 cost 1.97887e-07\n",
      "step 2000 training_accuracy 1.0 cost 1.08242e-06\n",
      "step 3000 training_accuracy 1.0 cost 1.00136e-07\n",
      "step 4000 training_accuracy 1.0 cost 2.6226e-08\n",
      "step 5000 training_accuracy 1.0 cost 1.90735e-08\n",
      "step 6000 training_accuracy 1.0 cost 1.43051e-08\n",
      "step 7000 training_accuracy 1.0 cost 1.21832e-06\n",
      "step 8000 training_accuracy 1.0 cost 5.24521e-08\n",
      "step 9000 training_accuracy 1.0 cost 2.47954e-07\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "batch_size = 50      # 한 루프에 몇개의 (Image, Label) 데이터를 학습하는지 설정\n",
    "display_step = 1000    # 루프를 돌면서 화면에 표시할 빈도 설정\n",
    "\n",
    "for i in range(10000):\n",
    "\tcostVal = 0.\n",
    "\tbatch = next_batch(batch_size)\n",
    "\t# 20번 돌릴 때마다 결과를 확인한다\n",
    "\tif i % display_step == 0:\n",
    "\t\ttrain_accuracy = sess.run(accuracy,feed_dict={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "\t\tcostVal = sess.run(cost, feed_dict={x: batch[0], y: batch[1], keep_prob:1.0})\n",
    "    \n",
    "\t\tprint('step', i , 'training_accuracy', train_accuracy,'cost', costVal)\n",
    "        \n",
    "        # 실제 학습과정 함수, dropout 50%를 토대로 학습한다\n",
    "\tsess.run(optimizer,feed_dict={x:batch[0],y:batch[1], keep_prob:0.5})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.642857\n"
     ]
    }
   ],
   "source": [
    "# 전부 학습이 끝나면 테스트 데이터를 넣어 정확도를 계산한다\n",
    "test_accuracy = sess.run(accuracy,feed_dict={x: lbp_img_test, y: test_labels, keep_prob: 1.0})\n",
    "print('test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [27]\n",
      "Prediction:  [27]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMMAAAD8CAYAAADKUxDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106edf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#----------------------------------------------\n",
    "# 임의의 얼굴 하나를 출력한 다음 맞혀보는 코드 \n",
    "r = random.randint(0, _num_examples -1)\n",
    "print (\"Label: \", sess.run(tf.argmax(test_labels[r:r+1], 1)))\n",
    "print (\"Prediction: \", sess.run(tf.argmax(y_conv, 1), {x:lbp_img_test[r:r+1], keep_prob:1.0}))\n",
    "\n",
    "plt.imshow(test_images[r:r+1].reshape(55, 40), cmap='gray', interpolation='nearest')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
